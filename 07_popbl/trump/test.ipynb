{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "import re, pickle\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_text.txt', 'r', encoding='utf8') as myfile:\n",
    "    raw_text = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(t):\n",
    "    # remove quotes\n",
    "    t = re.sub(r'\"@.*', '', t)\n",
    "    t = re.sub(r'^“.*”$', '', t)\n",
    "    # remove URLs\n",
    "    t = re.sub(r'https*:\\/\\/\\S*', '', t)\n",
    "    t = re.sub(r'pic\\.twitter\\.com\\/\\S*', '', t)\n",
    "    # remove \\n\n",
    "    t = re.sub('\\n', '', t)\n",
    "    # remove extra whitespaces\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    # replace '&amp' with 'and'\n",
    "    t = re.sub('&amp;', 'and', t) \n",
    "    return(t)\n",
    "\n",
    "raw_text = clean_tweet(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tweet_clf(t):\n",
    "    # clean\n",
    "    t = t.lower()\n",
    "    t = re.sub(\"'ll\", ' will', t) # replace abbreviations\n",
    "    t = re.sub(\"won't\", 'will not', t)\n",
    "    t = re.sub(\"n't\", ' not', t) \n",
    "    t = re.sub(r'@[A-Za-z0-9_]+', '', t) # remove @mention\n",
    "    t = re.sub(r'#[A-Za-z0-9_]+', '', t) # remove #tag\n",
    "    t = re.sub(r'[^a-zA-Z ]', '', t) # remove special characters\n",
    "    # remove stopwords \n",
    "    #stop = set(stopwords.words('english')) \n",
    "    #stop.update(['rt', 'cc']) \n",
    "    #stop = stop - set(['no', 'not', 'never']) \n",
    "    #t = [word for word in t.split(' ') if word not in stop] \n",
    "    #t = ' '.join(t)    \n",
    "    return t\n",
    "\n",
    "raw_text = prepare_tweet_clf(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"w\") as text_file:\n",
    "    text_file.write(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyone else sure there are about the first time I do and I was asking that the specific was looking at the solo station because really saying the best friend on their budget and the most particular page of the state with a bit over the raid on the trainer and the second thing I don't want to see wh\n",
      "\n",
      "0 texts collected.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4414f9ec0217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtextgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtextgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtextgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Programacion\\miniconda3\\envs\\deepl\\lib\\site-packages\\textgenrnn\\textgenrnn.py\u001b[0m in \u001b[0;36mtrain_from_file\u001b[1;34m(self, file_path, header, delim, new_model, context, is_csv, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 texts, context_labels=context_labels, **kwargs)\n\u001b[0;32m    366\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_from_largetext_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\Programacion\\miniconda3\\envs\\deepl\\lib\\site-packages\\textgenrnn\\textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[1;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, dropout, via_new_model, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m# indices_list = np.block(indices_list) # this hangs when indices_list is large enough\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m# FIX BEGIN ------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mindices_list_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()\n",
    "textgen.generate()\n",
    "\n",
    "textgen.train_from_file('test.txt', num_epochs=1)\n",
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
