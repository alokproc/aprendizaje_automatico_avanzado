{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Today we express our deepest gratitude to all ...\n",
       "1       Busy day planned in New York. Will soon be mak...\n",
       "2       Love the fact that the small groups of protest...\n",
       "3       Just had a very open and successful presidenti...\n",
       "4       A fantastic day in D.C. Met with President Oba...\n",
       "                              ...                        \n",
       "7370    I loved firing goofball atheist Penn @pennjill...\n",
       "7371    I hear @pennjillette show on Broadway is terri...\n",
       "7372    Irrelevant clown @KarlRove sweats and shakes n...\n",
       "7373    \"@HoustonWelder: Donald Trump is one of the se...\n",
       "7374    RT @marklevinshow: Trump: Rove is a clown and ...\n",
       "Name: Tweet_Text, Length: 7375, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv('trump.csv')['Tweet_Text']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = ''\n",
    "\n",
    "for row in tweets:\n",
    "    raw_text += row\n",
    "    raw_text += ' '\n",
    "    \n",
    "raw_text = raw_text.replace('\\n', ' ')\n",
    "raw_text = re.sub(r'http\\S+', '', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  779711\n",
      "Total Vocab:  79\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('chars.txt', 'wb') as fp:\n",
    "    pickle.dump(chars, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  701649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Total Patterns: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 553)               1227660   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 553)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 79)                43766     \n",
      "=================================================================\n",
      "Total params: 1,271,426\n",
      "Trainable params: 1,271,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(X_train, (len(X_train), seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(y_train)\n",
    "# define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(len(chars)*7, input_shape=(None, X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 631484 samples, validate on 70165 samples\n",
      "Epoch 1/10\n",
      "631484/631484 [==============================] - 213s 338us/sample - loss: 2.8124 - val_loss: 2.6293\n",
      "Epoch 2/10\n",
      "631484/631484 [==============================] - 207s 327us/sample - loss: 2.5468 - val_loss: 2.4504\n",
      "Epoch 3/10\n",
      "631484/631484 [==============================] - 214s 339us/sample - loss: 2.3972 - val_loss: 2.3321\n",
      "Epoch 4/10\n",
      "631484/631484 [==============================] - 206s 327us/sample - loss: 2.2813 - val_loss: 2.2357\n",
      "Epoch 5/10\n",
      "631484/631484 [==============================] - 215s 340us/sample - loss: 2.1897 - val_loss: 2.1784\n",
      "Epoch 6/10\n",
      "631484/631484 [==============================] - 214s 339us/sample - loss: 2.1137 - val_loss: 2.1065\n",
      "Epoch 7/10\n",
      "631484/631484 [==============================] - 206s 326us/sample - loss: 2.0504 - val_loss: 2.0686\n",
      "Epoch 8/10\n",
      "631484/631484 [==============================] - 199s 315us/sample - loss: 1.9958 - val_loss: 2.0308\n",
      "Epoch 9/10\n",
      "631484/631484 [==============================] - 201s 319us/sample - loss: 1.9462 - val_loss: 2.0099\n",
      "Epoch 10/10\n",
      "631484/631484 [==============================] - 204s 323us/sample - loss: 1.9047 - val_loss: 1.9866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e38408048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = [EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min', baseline=None)]\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=10, batch_size=128, callbacks=early_stop, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model02.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f653275e6a28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "X = np.reshape(X_test, (len(X_test), seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(y_test)\n",
    "\n",
    "score = model.evaluate(X, y, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
