{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AnomalyDetectionLSTMAutoEncoder.ipynb","provenance":[],"authorship_tag":"ABX9TyMTOkyJnvolvz3b/dDB56rU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"o_uUkQmeKCxJ","colab_type":"text"},"source":["En este ejercicio se utiliza un LSTM autoencoder para buscar anomalias en unos sensores de vibraciones colocados en unos rodamientos"]},{"cell_type":"markdown","metadata":{"id":"h_3_xxXHKOa7","colab_type":"text"},"source":["Primero importamos las librerias"]},{"cell_type":"code","metadata":{"id":"5mr7rLeRG8uG","colab_type":"code","outputId":"97d7cadc-5e8c-44a0-d043-fa94ff92a905","executionInfo":{"status":"error","timestamp":1588469221408,"user_tz":-120,"elapsed":3067,"user":{"displayName":"Ekhi Zugasti Uriguen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64","userId":"00195558535022081217"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["#_________________TODO_______________________\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4110c6d44912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmerged_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdataset_mean_abs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/2nd_test'"]}]},{"cell_type":"markdown","metadata":{"id":"8-ZI8CjNKx9Z","colab_type":"text"},"source":["Importamos datos, y preprocesamos.\n","\n","En vez de utilizar todos los datos de cada csv, calcularemos la media de cada sensor por archivo, y lo juntaremos en un único pandas dataframe, donde el index, será la fecha y la hora."]},{"cell_type":"code","metadata":{"id":"_kVYLXQOKrMX","colab_type":"code","colab":{}},"source":["# load, average and merge sensor samples\n","data_dir = 'XXXXXXXX'\n","merged_data = pd.DataFrame()\n","\n","for filename in os.listdir(data_dir):\n","  #_____________________TODO__________________________________________-\n","    #read CSV\n","    #calculate mean value of sensors\n","\n","    #append to \"merged_data\" and add index value date and time (you have that information in the filename)\n","\n","merged_data.columns = ['Bearing 1', 'Bearing 2', 'Bearing 3', 'Bearing 4']\n","\n","#transform data file index to datetime and sort in chronological order\n","merged_data.index = pd.to_datetime(merged_data.index, format='%Y.%m.%d.%H.%M.%S')\n","merged_data = merged_data.sort_index()\n","merged_data.to_csv('Averaged_BearingTest_Dataset.csv')\n","print(\"Dataset shape:\", merged_data.shape)\n","merged_data.head()\n","\n","\n","train = merged_data['2004-02-12 10:52:39': '2004-02-15 12:52:39']\n","test = merged_data['2004-02-15 12:52:39':]\n","print(\"Training dataset shape:\", train.shape)\n","print(\"Test dataset shape:\", test.shape)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0ZRH-UsL2mD","colab_type":"text"},"source":["Plot training and testing data "]},{"cell_type":"code","metadata":{"id":"m5NuI6myKTIB","colab_type":"code","colab":{}},"source":["\n","\n","\n","fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n","ax.plot(train['Bearing 1'], label='Bearing 1', color='blue', linewidth=1)\n","ax.plot(train['Bearing 2'], label='Bearing 2', color='red', linewidth=1)\n","ax.plot(train['Bearing 3'], label='Bearing 3', color='green', linewidth=1)\n","ax.plot(train['Bearing 4'], label='Bearing 4', color='black', linewidth=1)\n","plt.legend(loc='lower left')\n","ax.set_title('Bearing Sensor Training Data', fontsize=16)\n","plt.show()\n","\n","fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n","ax.plot(test['Bearing 1'], label='Bearing 1', color='blue', linewidth=1)\n","ax.plot(test['Bearing 2'], label='Bearing 2', color='red', linewidth=1)\n","ax.plot(test['Bearing 3'], label='Bearing 3', color='green', linewidth=1)\n","ax.plot(test['Bearing 4'], label='Bearing 4', color='black', linewidth=1)\n","plt.legend(loc='lower left')\n","ax.set_title('Bearing Sensor Testing Data', fontsize=16)\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RvAef_frMFk4","colab_type":"text"},"source":["Scale with MinMaxScaler and reshape data to be tensor inputs for lstm"]},{"cell_type":"code","metadata":{"id":"OkUIwtEoMGAe","colab_type":"code","colab":{}},"source":["#_________TODO_________________\n","#minmaxscale\n","\n","\n","# reshape inputs for LSTM [samples, timesteps, features]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bjiOcIr8Mkxc","colab_type":"text"},"source":["Define Autoencoder model (LSTM autoencoder)\n","compile and fit"]},{"cell_type":"code","metadata":{"id":"b9VcgQcqMlBw","colab_type":"code","colab":{}},"source":["\n","\n","# define the autoencoder network model\n","def autoencoder_model(X):\n","    inputs = Input(shape=(X.shape[1], X.shape[2]))\n","    L1 = LSTM(16, activation='relu', return_sequences=True,)(inputs)\n","    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n","    L3 = RepeatVector(X.shape[1])(L2)\n","    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n","    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n","    output = TimeDistributed(Dense(X.shape[2]))(L5)\n","    model = Model(inputs=inputs, outputs=output)\n","    return model\n","\n","#_________TODO________________ compile, and fit\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YwP27beIMlTU","colab_type":"text"},"source":["Plot loss history"]},{"cell_type":"code","metadata":{"id":"2ivWEU3pMleb","colab_type":"code","colab":{}},"source":["# plot the training losses\n","fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n","ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n","ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n","ax.set_title('Model loss', fontsize=16)\n","ax.set_ylabel('Loss (mae)')\n","ax.set_xlabel('Epoch')\n","ax.legend(loc='upper right')\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VR_SnzdlNTG6","colab_type":"text"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","Predict Train"]},{"cell_type":"code","metadata":{"id":"2GbQ2YfJNhT2","colab_type":"code","colab":{}},"source":["#make the prediction of Xtrain values\n","#_______TODO_____________\n","X_pred=#Todo"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2tKg0-m3Npoj","colab_type":"text"},"source":["Calculate the MAE loss in training phase and set threshold"]},{"cell_type":"code","metadata":{"id":"ojfzSsEHNpyI","colab_type":"code","colab":{}},"source":["LossMAE = np.mean(np.abs(X_pred-Xtrain), axis = 1)\n","thres=LossMAE.mean()+3*LossMAE.std()\n","print(thres)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7MmTg61OHAB","colab_type":"text"},"source":["calculate the loss on the test set"]},{"cell_type":"code","metadata":{"id":"7l1WByhFOHS0","colab_type":"code","colab":{}},"source":["#Make prediction of Xtest, and calculate the loss MAE of the test set\n","#________TODO__________________-"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BvB4tWUtOVAB","colab_type":"text"},"source":["Plot, train MAE losses, threshold and TestMAE looses"]},{"cell_type":"code","metadata":{"id":"1QGXv6UbOrlZ","colab_type":"code","colab":{}},"source":["#____________TODO__________________-"],"execution_count":0,"outputs":[]}]}