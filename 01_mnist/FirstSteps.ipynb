{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l508vsuXa84g"
   },
   "source": [
    "# First models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhfaWqjga84p"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNG6EVhSa84u"
   },
   "source": [
    "The first step of all modeling is the preparation and loading of the data. In our case, the MNIST problem, which consists of a large database of written digits and is so common that it has become a paradigmatic example within Machine Learning.\n",
    "\n",
    "The pre-processing work required to be able to apply a model to this problem is not minor but, fortunately, Keras provides a direct instruction to download the images representing the thousands of handwritten digits (already with a unified format of 28x28 pixels in grayscale).\n",
    "\n",
    "In order to load the data that Keras brings as an example, you have to follow two steps: first, load the Keras library that provides the tools to work with the specific dataset (which is usually in the package keras.datasets, in this case called mnist); and, second, execute the process of loading the data (the library provides the function load_data()). It must be taken into account that the first time this process is carried out, the data is downloaded from a repository that comes by default predefined in that package, since, due to its size, it is not installed together with the library, but only when the user needs it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqSfLO6Ga84x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsJzcWVva85A"
   },
   "source": [
    "We can explore a bit how each of these variables are by using specific Python instructions that give us information about their structure and show the first values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1584901981396,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "iO-_m7ara85D",
    "outputId": "7c79e741-94be-4948-c28e-875f824971e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1584901983497,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "4tmn854da85M",
    "outputId": "372dba4b-e5a5-4565-c646-e688db001e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1584901986607,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "47unI6QLa85T",
    "outputId": "0b196741-ca4c-4fdd-a5b5-6027fdd196cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1584901989418,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "Srz8GaNxa85b",
    "outputId": "76f8e877-063b-4af6-e1e8-5cd555a344d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1584901993555,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "xS4rJQc3a85h",
    "outputId": "893db52a-18d5-4131-a30d-dfdf067bdf22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1584901995479,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "DhHdqCYka85n",
    "outputId": "40771617-9837-456e-da26-19fcebabbcf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hUacjDOa85u"
   },
   "source": [
    "If we want to see some of the images in the dataset, we can make use of the appropriate instruction from, for example, the matplotlib library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1584902120547,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "lLpxIH2Ka85v",
    "outputId": "9f3b7c37-4178-4c07-d1d8-3104b5cf5b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2063803fb08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(test_data[0],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4v_QzUWa852"
   },
   "source": [
    "The workflow is similar to the one that is always followed in the Supervised ML processes, and which we have analyzed in the previous term:\n",
    "- We show the model (a neural network, in our case) the training data, train_data and train_labels.\n",
    "- The model must learn to associate the images with the associated labels.\n",
    "- Finally, we verify the learning done by checking on test_data that the answers given by the model (predictions) coincide with those stored in test_labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaXYVWn_a853"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IskhkxDGa855"
   },
   "source": [
    "We are already in a position to define a neural network that will consume the above data to see if we are able to provide a first solution to the problem of handwritten digit recognition. As we are only making a first approximation to Keras, the defined network will be very basic, with only one input and one output layer:\n",
    "- We are going to place an input layer with 784 (= 28 * 28) neurons (which will receive each of the 784 pixels of each image), with ReLU activation function, and\n",
    "- an output layer with 10 neurons (one neuron for each of the possible output labels), and with softmax activation (so it can be interpreted as an output probability that indicates how likely it is that the input image will have each of the labels as output):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1584902432535,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "5WE2S6VDa858",
    "outputId": "5d0f3fa8-8762-4485-aaf8-d3aa7afda308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "nn.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "nn.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1584902438951,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "RtPMsoe7iyhV",
    "outputId": "d5858b8b-3191-4617-8052-c500f01070cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(nn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiOvsbPRa86C"
   },
   "source": [
    "In addition to neurons, which are the atomic units that make up a neural network, from a functional point of view, the basic element of neural networks is what is known as a layer, a processing module formed by a set of equal neurons that can be interpreted as a \"filter\" of data.\n",
    "\n",
    "Most of Deep Learning, and where it is demonstrating an added value with respect to the other existing ML models, consists of concatenating simple layers (and, possibly, with specific differentiated functionalities) to obtain a computing device that processes data progressively.\n",
    "\n",
    "In the case of the network we have defined, this device consists of a sequence of two dense layers, which are totally connected neural layers. The second (and last) layer is a \"softmax\" layer of 10 outputs, which means that it will return a probability vector of 10 values (i.e. 10 values in [0, 1] that add up to 1). Each of these values will interpret the probability that the current image belongs to one of the 10 classes (the digits from 0 to 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ze7fz5Ca86E"
   },
   "source": [
    "So far we have only defined the structure of the network, but we have not given any information about how the training will be carried out. To do this we have to tell Keras some additional features, such as the optimizer that will allow us to modify the weights of the net, which target (error) function will be used to drive this optimization, and the metrics that we will use to measure how the net behaves as it is trained.\n",
    "\n",
    "Keras provides the compile function that allows you to set these (and other) properties on an already defined network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38nJaSA8a86G"
   },
   "outputs": [],
   "source": [
    "nn.compile(optimizer='rmsprop',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9ADyVoma86M"
   },
   "source": [
    "Since the neural network we are going to use must receive as input data each image in a flattened form (i.e. not as a 28x28 matrix, but as a 28x28=784 position vector), our first step is to make use of the instructions provided by Keras to transform the form of the input data.\n",
    "\n",
    "In addition, we will take advantage to normalize the content of these images (they are in grayscales with uint8 values between 0 and 255, and we will pass them to float32 values in [0, 1]), something advisable when working with this type of models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ-nOdCza86N"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.reshape((60000, 28 * 28))\n",
    "train_data = train_data.astype('float32') / 255\n",
    "\n",
    "test_data = test_data.reshape((10000, 28 * 28))\n",
    "test_data = test_data.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Bgz_zzda86V"
   },
   "source": [
    "In addition, we will convert the tags (which come in the dataset as integer values), into binary vectors to correspond to the output that our network can provide:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4qLTiD9a86X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1584902682735,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "Osi9d4etj44Q",
    "outputId": "e34f5743-30e8-470e-acb8-e907bfa838d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbVqLhywa86d"
   },
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0naR8BDaa86e"
   },
   "source": [
    "Once the data is prepared and the network is defined (structure and functionality), we can make use of the fit instruction to start the training process on the data we have. Essentially, we have to indicate on which data to train (input and output), how many iterations (epochs) and with which batch size (how often the algorithm updates the weights).\n",
    "\n",
    "During the training process, Keras informs about the values that the objective function takes, as well as the metric/s that we have set in the compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22610,
     "status": "ok",
     "timestamp": 1584902786853,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "0EZh-z1pa86g",
    "outputId": "d1561f80-d484-4f6d-a998-568f42e5e5c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2510 - accuracy: 0.9273\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.1018 - accuracy: 0.9700\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0677 - accuracy: 0.9797\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0488 - accuracy: 0.9852\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0364 - accuracy: 0.9891\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0280 - accuracy: 0.9915\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0171 - accuracy: 0.9950\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0126 - accuracy: 0.9964\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 8.7630e-04 - accuracy: 0.9998\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 8.0828e-04 - accuracy: 0.9998\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 4.6692e-04 - accuracy: 0.9999\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 3.5372e-04 - accuracy: 0.9999\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 3.6737e-04 - accuracy: 0.9999\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 4.6565e-04 - accuracy: 0.9999\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 3.2502e-04 - accuracy: 0.9999\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4517e-04 - accuracy: 0.9999\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1315e-04 - accuracy: 0.9999\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.8722e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2546e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4790e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 6.4901e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1864e-04 - accuracy: 0.9999\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 4.6811e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.4019e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2456e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.7074e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.0031e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 4.8719e-06 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 6.1229e-06 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 3.0533e-07 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.9683e-07 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2092e-07 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4037e-07 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 4.4889e-08 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1136e-08 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7297e-08 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.5791e-08 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4752e-08 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.3687e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20633109388>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_data, train_labels, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErFbIAyPa86l"
   },
   "source": [
    "We must keep in mind that the values shown are the error and metrics calculated on the training data itself. However, since the goal of a learning model is to generalize well on data that the training process has not seen before, we need the test set to evaluate how the network behaves on examples it has not used to fit.\n",
    "\n",
    "On the training data we quickly reach an accuracy of 0.989 (i.e. 98.9%), but let's see how well it behaves on the test data (that it has not used to learn):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1584902827805,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "Y5IbPigHa86n",
    "outputId": "35ba8318-3d04-42a7-b46a-89218d4ba5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.1391 - accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = nn.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1584902835242,
     "user": {
      "displayName": "Ekhi Zugasti Uriguen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjLW21F9JMtJwfUDFcY2ROtJC3l1QPlGpvoN9Qy=s64",
      "userId": "00195558535022081217"
     },
     "user_tz": -60
    },
    "id": "sCvxZqW_a86s",
    "outputId": "1c8674aa-792d-48f2-88c6-d8c220209e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9846\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5mg3dCrqEyp"
   },
   "source": [
    "# Mini Exercise\n",
    "\n",
    "use the Image that you can find in the drive, and make a prediction with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ba1iW_OTkq5I"
   },
   "source": [
    "## Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6aJG0hckzmG"
   },
   "source": [
    "\n",
    "\n",
    "This example has was not created taking into account the general ML workflow that was explained in class. We have a model that has statistical power. so, following the universal ml workflow:\n",
    "1. defining the problem and assembling a dataset (done)\n",
    "2. choose a measure of success (done, but can be changed)\n",
    "3. Deciding on an evaluation protocol (done, but can be changed)\n",
    "4. preparing your data (done)\n",
    "5. Developing first model (done)\n",
    "6. scaling up (not done)\n",
    "7. regularizing the model (not done)\n",
    "8. tuning hyperparameters (not done) (use GridSearchCV)\n",
    "\n",
    "\n",
    "> https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "\n",
    "9. validating the model (done, but must be re-done)\n",
    "\n",
    "Please, finalize the ML workflow in order to match the universal ML workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FirstSteps.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
