{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4n_92HtC8lf"
   },
   "source": [
    "# Generación de texto con LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qJVMD08C8lm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: importar librerías\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_pMK7n-C8l1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194254"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paso 2: importar cuento  + pasar todo a minusculas + pasar caracteres a integers\n",
    "# load ascii text and covert to lowercase\n",
    "f = open('MobyDick.txt', 'r', encoding=\"utf8\") \n",
    "text = f.read()\n",
    "f.close()\n",
    "text = text.lower()\n",
    "text = re.sub(r\"[^a-zA-Z0-9]+\", ' ', text)\n",
    "#text = text[:100000]\n",
    "\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = np.array(list(text))\n",
    "encoder = preprocessing.LabelEncoder().fit(chars)\n",
    "encoded_chars = encoder.transform(chars)\n",
    "\n",
    "# normalize data\n",
    "mean = encoded_chars.mean()\n",
    "stdv = encoded_chars.std()\n",
    "encoded_chars = (encoded_chars - mean) / stdv\n",
    "\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyvuR3l7C8l-"
   },
   "outputs": [],
   "source": [
    "#paso 3: preparar datos: \n",
    "# 1- preprocesar: ejemplo: CHAPT -> E; HAPTE -> R (pero con 100 caracteres)\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps, n_step_diff=1):\n",
    "    X, y = list(), list()\n",
    "    i = 0\n",
    "    while i <len(sequence): \n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        i = i + (n_step_diff)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = split_sequence(encoded_chars, 100, 100)\n",
    "\n",
    "# 2- cambiar dataset para que la entrada sea válida: [Samples, time_steps,features]\n",
    "n_samples = X_train.shape[0]\n",
    "n_steps = X_train.shape[1] # 100\n",
    "n_features = 1\n",
    "X_train = X_train.reshape((n_samples, n_steps, n_features))\n",
    "\n",
    "# 3-Normalizar\n",
    "    # normalizamos todo después de usar label encoder\n",
    "\n",
    "# prepare the dataset of input to output pairs encoded as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIqkVhwYC8mG"
   },
   "outputs": [],
   "source": [
    "# Preparar datos de salida (one-hot encoder)\n",
    "# one hot encode the output variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBU8GojbC8mP"
   },
   "outputs": [],
   "source": [
    "# Definimos modelo LSTM\n",
    "lstm_model = models.Sequential([\n",
    "    layers.LSTM(32, input_shape=X_train.shape[-2:]),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iZiLTxXC8mX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7165 samples, validate on 4777 samples\n",
      "Epoch 1/5\n",
      "7165/7165 [==============================] - 14s 2ms/step - loss: 0.9305 - val_loss: 0.9008\n",
      "Epoch 2/5\n",
      "7165/7165 [==============================] - 14s 2ms/step - loss: 0.9125 - val_loss: 0.8998\n",
      "Epoch 3/5\n",
      "7165/7165 [==============================] - 14s 2ms/step - loss: 0.9080 - val_loss: 0.8868\n",
      "Epoch 4/5\n",
      "7165/7165 [==============================] - 14s 2ms/step - loss: 0.9035 - val_loss: 0.8834\n",
      "Epoch 5/5\n",
      "7165/7165 [==============================] - 14s 2ms/step - loss: 0.8997 - val_loss: 0.8807\n"
     ]
    }
   ],
   "source": [
    "#Hacemos el FIT\n",
    "history = lstm_model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6gqVfaMC8md"
   },
   "outputs": [],
   "source": [
    "#Generar datos caracteres\n",
    "# pick a random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXNlBKIaC8mo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsMghE2JC8mv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MobyDick.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
