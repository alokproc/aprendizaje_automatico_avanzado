{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b46897WqUF5p"
   },
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbPcDjv_UNre"
   },
   "source": [
    "## Part 1: Preprocess the data.\n",
    "In the csv files, you will find several columns. you only need the \"close\" column for this exercise\n",
    "\n",
    "\n",
    "reshape the data! see examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zp2Fl7aJMNGi"
   },
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "\n",
    "\n",
    "# Importing the training set\n",
    "\n",
    "\n",
    "# Creating a data structure with 30 timesteps and 1 output\n",
    "\n",
    "\n",
    "# Reshaping [samples,timesteps,features]\n",
    "# remember: samples: how many observations you have\n",
    "#           timesteps: how long does the rnn remember (30 in our case)\n",
    "#           features: how many variables (1 in our case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "df_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "close_train = df_train['Close']\n",
    "close_train = close_train.astype(str).str.replace(',', '')\n",
    "close_train = pd.to_numeric(close_train)\n",
    "\n",
    "# test\n",
    "df_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "close_test = df_test['Close']\n",
    "close_test = close_test.astype(str).str.replace(',', '')\n",
    "close_test = pd.to_numeric(close_test)\n",
    "close_test = np.concatenate([np.zeros(30), close_test])\n",
    "\n",
    "# normalize data\n",
    "mean = close_train.mean()\n",
    "stdv = close_train.std()\n",
    "close_train = (close_train - mean) / stdv\n",
    "close_test = (close_test - mean) / stdv\n",
    "\n",
    "# print shapes\n",
    "print(close_train.shape)\n",
    "print(close_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.29789921 -0.28053984 -0.33662394 ... -0.65807564 -0.62001857\n",
      "  -0.63476796]\n",
      " [-0.28053984 -0.33662394 -0.39106921 ... -0.62001857 -0.63476796\n",
      "  -0.66020003]\n",
      " [-0.33662394 -0.39106921 -0.55786477 ... -0.63476796 -0.66020003\n",
      "  -0.65437312]\n",
      " ...\n",
      " [ 0.14209387  0.27811601  0.31447356 ...  0.47702032  0.46882622\n",
      "   0.47878054]\n",
      " [ 0.27811601  0.31447356  0.35544408 ...  0.46882622  0.47878054\n",
      "   0.43932744]\n",
      " [ 0.31447356  0.35544408  0.29055891 ...  0.47878054  0.43932744\n",
      "   0.4256099 ]]\n",
      "(1228, 30) \n",
      "\n",
      "[-0.66020003 -0.65437312 -0.66578417 ...  0.43932744  0.4256099\n",
      "  0.35902521]\n",
      "(1228,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = split_sequence(close_train, 30)\n",
    "print(X_train)\n",
    "print(X_train.shape, '\\n')\n",
    "print(y_train)\n",
    "print(y_train.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_samples = X_train.shape[0] # 1228\n",
    "n_steps = X_train.shape[1] # 30\n",
    "n_features = 1 # \"close\" column\n",
    "\n",
    "X_train = X_train.reshape((n_samples, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting sources\n",
    "# https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "# https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "# https://machinelearningmastery.com/stacked-long-short-term-memory-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJVFwheNZA0x"
   },
   "source": [
    "## part 2: model building\n",
    "Build The RNN, you can use LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYsW6xAlMNGw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 32)            4352      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 982 samples, validate on 246 samples\n",
      "Epoch 1/20\n",
      "982/982 [==============================] - 2s 2ms/step - loss: 0.3151 - val_loss: 0.0189\n",
      "Epoch 2/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2391 - val_loss: 0.0166\n",
      "Epoch 3/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1960 - val_loss: 0.0147\n",
      "Epoch 4/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2034 - val_loss: 0.0142\n",
      "Epoch 5/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1933 - val_loss: 0.0140\n",
      "Epoch 6/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1686 - val_loss: 0.0096\n",
      "Epoch 7/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1770 - val_loss: 0.0129\n",
      "Epoch 8/20\n",
      "982/982 [==============================] - 1s 2ms/step - loss: 0.2071 - val_loss: 0.0099\n",
      "Epoch 9/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1921 - val_loss: 0.0084\n",
      "Epoch 10/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2164 - val_loss: 0.0084\n",
      "Epoch 11/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1703 - val_loss: 0.0081\n",
      "Epoch 12/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1759 - val_loss: 0.0113\n",
      "Epoch 13/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1631 - val_loss: 0.0110\n",
      "Epoch 14/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.2271 - val_loss: 0.0078\n",
      "Epoch 15/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1823 - val_loss: 0.0075\n",
      "Epoch 16/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1791 - val_loss: 0.0080\n",
      "Epoch 17/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1756 - val_loss: 0.0100\n",
      "Epoch 18/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1529 - val_loss: 0.0099\n",
      "Epoch 19/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1334 - val_loss: 0.0104\n",
      "Epoch 20/20\n",
      "982/982 [==============================] - 1s 1ms/step - loss: 0.1493 - val_loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras import models, layers\n",
    "\n",
    "# Initialising the RNN\n",
    "lstm_model = models.Sequential([\n",
    "    layers.LSTM(32, dropout=0.1, recurrent_dropout=0.5, return_sequences=True, input_shape=X_train.shape[-2:]),\n",
    "    layers.LSTM(32, dropout=0.1, recurrent_dropout=0.5),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "print(lstm_model.summary())\n",
    "\n",
    "# Compiling the RNN\n",
    "lstm_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "history = lstm_model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4CJcwf6ZaCD"
   },
   "source": [
    "## Part 3: Making Predictions\n",
    "make predictions in the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3yRQGt_MNG-"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = split_sequence(close_test, 30)\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_samples = X_train.shape[0]\n",
    "n_steps = X_train.shape[1] # 30\n",
    "n_features = 1 # \"close\" column\n",
    "\n",
    "X_train = X_train.reshape((n_samples, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZFthMDbMNHH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 499us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1290276050567627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.evaluate(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GoogleStockPrice-exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
